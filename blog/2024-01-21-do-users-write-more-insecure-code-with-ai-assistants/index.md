---
slug: do-users-write-more-insecure-code-with-ai-assistants
title: Do Users Write More Insecure Code with AI Assistants?
authors: scherersebastian
tags: [Security, AI]
---

# Do Users Write More Insecure Code with AI Assistants?

The paper _"Do Users Write More Insecure Code with AI Assistants?"_ focuses on a study examining user interactions with an AI Code assistant in programming tasks, particularly those involving security. The main findings are:

1. **Decreased Code Security with AI Assistance**: Users who utilized an AI assistant, specifically based on OpenAI's codex-davinci-002 model, tended to write code that was significantly less secure compared to those who did not use the assistant.

2. **Perception vs. Reality**: There was a notable discrepancy in perception among users who had access to the AI assistant; they were more likely to believe their code was secure, even though it was less secure in reality.

3. **Impact of User Engagement and Trust**: The study found that users who were less trusting of the AI and who actively modified their prompts (e.g., by re-phrasing questions or adjusting settings) produced code with fewer security vulnerabilities.

<!--truncate-->

The study aims to inform the development of future AI-based coding assistants by providing a detailed analysis of how users interact with these tools and the impact on code security. The authors also released the user interface used in the study to encourage similar research in the future. This paper contributes to the broader understanding of the implications of AI assistance in coding, especially in the context of writing secure code.

We'll see what the future holds.

## References

- [Do Users Write More Insecure Code with AI Assistants? - Neil Perry, Megha Srivastava, Deepak Kumar, Dan Boneh](https://arxiv.org/abs/2211.03622)
